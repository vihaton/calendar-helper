{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import numpy as np\n",
    "import arrow\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from source.utils import authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = False\n",
    "download_all_events = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = authenticate(verbose=True)\n",
    "service = build('calendar', 'v3', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calendars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = service.calendarList().list().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_citem(citem):\n",
    "    print('Summary:\\t' + citem['summary'])\n",
    "    print('id:\\t\\t' + citem['id'])\n",
    "    print('***********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for citem in clist['items']:\n",
    "    print_citem(citem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary calendar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_default_calendar(clist):\n",
    "    for citem in clist['items']:\n",
    "        if citem.get('primary', False):\n",
    "            print_citem(citem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_default_calendar(clist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_colors = service.colors().get().execute()['event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {k: v['background'] for k, v in event_colors.items()}\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 2))\n",
    "for i, (num, color) in enumerate(colors.items()):\n",
    "    rect = mpatches.Rectangle((i, 0), 1, 1, facecolor=color)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(i + 0.5, 0.5, num, ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(0, len(colors))\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_col = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyfile = data_dir + 'col2meaning.json'\n",
    "with open(keyfile, 'r') as fo:\n",
    "    col2meaning = json.load(fo)\n",
    "col2meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_type(etype: str, year:str = \"default\", col2meaning=col2meaning):\n",
    "    if not isinstance(etype, str):\n",
    "        etype = str(etype)\n",
    "    if not isinstance(year, str):\n",
    "        year = str(year)\n",
    "\n",
    "    if year in col2meaning and etype in col2meaning[year]:\n",
    "        return col2meaning[year][etype]\n",
    "    elif etype in col2meaning[\"default\"]:\n",
    "        return col2meaning[\"default\"][etype]\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = list(col2meaning[\"default\"].values())\n",
    "# if 'default' in types:\n",
    "#     types.remove('default')\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2014,1,1)\n",
    "end = datetime(start.year + 1, 1,1)\n",
    "now = arrow.get(datetime.now().isoformat() + '+02:00').datetime\n",
    "\n",
    "end = now\n",
    "\n",
    "start, end, now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_event(e):\n",
    "    print('Summary:\\t' + e.get('summary', 'summary'))\n",
    "    print('ColorId:\\t' + e.get('colorId', 'unknown'))\n",
    "    print('Start:\\t\\t' + str(e.get('start', 'start')))\n",
    "    print('End:\\t\\t' + str(e.get('end', 'end')))\n",
    "    print('Status:\\t\\t' + e.get('status', 'status'))\n",
    "    print('====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_req(min_ts = start.isoformat() + 'Z', max_ts = end.isoformat() + 'Z'):\n",
    "\n",
    "    print('get everything since', min_ts, 'until', max_ts)\n",
    "\n",
    "    req_orig = service.events().list(calendarId='primary',\n",
    "                                          timeMin=min_ts,\n",
    "                                          #timeMax=max_ts,\n",
    "                                          #maxResults=15, \n",
    "                                          singleEvents=True,\n",
    "                                          orderBy='startTime')\n",
    "    return req_orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_orig = prepare_req()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "col2meaning = { \n",
    "    e.get('colorId'): e.get('summary') for e in events[:-3]\n",
    "}\n",
    "\n",
    "col2meaning\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_event_res(events_result):\n",
    "    print(f'got {len(events_result.get(\"items\", []))} results')\n",
    "    print('next page token:  ' + events_result.get('nextPageToken', 'no next page'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "events_result = req_orig.execute()\n",
    "events = events_result.get('items', [])\n",
    "print_event(events[0])\n",
    "\n",
    "print_event_res(events_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_datetime(time_obj):\n",
    "    if type(time_obj) == datetime or type(time_obj) == 'float':\n",
    "        return time_obj\n",
    "    \n",
    "    if 'date' in time_obj:\n",
    "        s = time_obj['date']\n",
    "    elif 'dateTime' in time_obj:\n",
    "        s = time_obj['dateTime']\n",
    "    else:\n",
    "        s = time_obj\n",
    "        \n",
    "    return arrow.get(s).datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_events(verbose=False):\n",
    "    events = []\n",
    "    prev_req = req_orig = prepare_req()\n",
    "    events_result = req_orig.execute()\n",
    "\n",
    "    events.append(events_result.get('items', []))\n",
    "    prev_res = events_result\n",
    "\n",
    "    i = 0\n",
    "    while prev_req is not None:\n",
    "        print(f'round {i}', end='\\r')\n",
    "        prev_req = service.events().list_next(prev_req, prev_res)\n",
    "        if prev_req is None:\n",
    "            break\n",
    "        prev_res = prev_req.execute()\n",
    "        \n",
    "        if verbose: \n",
    "            print_event_res(prev_res)\n",
    "\n",
    "        res_events = prev_res.get('items', [])\n",
    "\n",
    "        events.append(res_events)\n",
    "\n",
    "        last_start = parse_to_datetime(res_events[-1].get('start'))\n",
    "        if last_start > now:\n",
    "            print('last start was in the future, we can stop', last_start)\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    print('Finished fetching all the events')\n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_event(e):\n",
    "    start = e.get('start')\n",
    "    col = e.get('colorId', '0')\n",
    "    end = e.get('end')\n",
    "    summary = e.get('summary', '')\n",
    "\n",
    "    whole_day = 'date' in start\n",
    "    \n",
    "    start = parse_to_datetime(start)\n",
    "    end = parse_to_datetime(end)\n",
    "\n",
    "    duration_s = (end - start).total_seconds() # <-- total seconds would compute also the full day events\n",
    "    t = col2meaning[col]\n",
    "\n",
    "    return {\n",
    "        'start': start,\n",
    "        'type': t,\n",
    "        'summary': summary,\n",
    "        'duration_s': duration_s,\n",
    "        'whole_day': whole_day,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_datetime_by_week(ts):\n",
    "    year, week = ts.isocalendar()[:2]\n",
    "    return datetime.strptime(f'{year}-{min(week*7, 365)}', \"%Y-%j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter(ts):\n",
    "    mon = ts.month\n",
    "    quartal = mon // 3\n",
    "    quartal += 1 if mon % 3 != 0 else 0 \n",
    "    return quartal\n",
    "\n",
    "def get_invoiced_quarter(ts):\n",
    "    if type(ts) is float:\n",
    "        return 666 # ts was not defined\n",
    "    \n",
    "    assert type(ts) is str, 'expected timestamp to be a string'\n",
    "    mon = int(ts[5:7])\n",
    "    quartal = mon // 3\n",
    "    quartal += 1 if mon % 3 != 0 else 0 \n",
    "    return quartal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and save the events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_events(df, time_str):\n",
    "    df.to_csv(data_dir + f'calendar_events_until_{time_str}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if download_all_events:\n",
    "    events = download_events()\n",
    "    # includes all recurring future events as well\n",
    "    events = np.concatenate(events) if type(events) is list else events\n",
    "    print('events.shape', events.shape)\n",
    "    \n",
    "    print('available fields')\n",
    "    print(events[0].keys())\n",
    "    print()\n",
    "    \n",
    "    print_event(events[0])\n",
    "    print_event(events[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_all_events:\n",
    "    print('parsing events...')\n",
    "    events_parsed = [ parse_event(e) for e in events ]\n",
    "    \n",
    "    events_all = pd.DataFrame(data=events_parsed)\n",
    "\n",
    "    yesterday = now - timedelta(days=1)\n",
    "    print(yesterday)\n",
    "    \n",
    "    hist_df = events_all[events_all.start < yesterday]\n",
    "\n",
    "    save_events(hist_df, yesterday.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
    "    print('hist df saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the events from disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_dir(directory, return_dirs=False, verbose=False):\n",
    "    if not os.path.exists(directory):\n",
    "        raise Exception(f'{directory} does not exist!')\n",
    "    for (path, dirs, files) in os.walk(directory):\n",
    "        if verbose:\n",
    "            print('path: ', path)\n",
    "            print('dirs', dirs)\n",
    "            print('files')\n",
    "            for i, file in enumerate(files):\n",
    "                print('\\t', i, file)\n",
    "        break\n",
    "    return files if not return_dirs else (files, dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files_in_dir(data_dir)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "assert files[ind].split('.')[-1] in 'csv', f'file was not a csv file! it was {files[ind]}'\n",
    "\n",
    "events_file = data_dir + files[ind]\n",
    "print(f'load events from file {events_file}')\n",
    "\n",
    "with open(events_file, 'rb') as fo:\n",
    "    events_all = pd.read_csv(events_file)\n",
    "    \n",
    "events_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_all.groupby(\"type\").agg({'summary': lambda x: x.unique()[-10:]}).reset_index().sort_values('type').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Durations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_durations(df):\n",
    "    df['duration_min'] = df['duration_s'] / 60\n",
    "    df['duration_h'] = df['duration_min'] / 60\n",
    "    df['duration_d'] = df['duration_h'] / 24\n",
    "    df['is_full_day'] = (df['duration_d'] >= 1) & (df['duration_h'] % 24 - 0 < 1e-6)\n",
    "    df['whole_day'] = df['whole_day'] | df['is_full_day'] # this adds couple outlier events\n",
    "    df['is_over_24h'] = df['duration_h'] > 24\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_all = process_durations(events_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_all[~events_all.is_full_day & events_all.whole_day] # should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_all[events_all.duration_d >= 1].sort_values('duration_d', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dates(df):\n",
    "    df['start'] = df.start.apply(lambda ts: parse_to_datetime(ts))\n",
    "    df['year'] = df.start.apply(lambda ts: ts.year) #datetime.strptime(f'{ts.year}-1-1', '%Y-%m-%d'))\n",
    "    df['year_mon'] = df.start.apply(lambda ts: datetime.strptime(f'{ts.year}-{ts.month}-1', '%Y-%m-%d'))\n",
    "    df['mon'] = df.start.apply(lambda ts: datetime.strptime(f'2000-{ts.month}-1', '%Y-%m-%d'))\n",
    "    df['year_week'] = df.start.apply(group_datetime_by_week)\n",
    "    df['quarter'] = df.start.apply(get_quarter)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_all = process_dates(events_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = events_all.year.max()\n",
    "print('max year', max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events_all[(events_all.whole_day == False) & (events_all.is_over_24h == False)]\n",
    "events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_missing_types(data, time_col='year_week', unique_times=None, col2meaning=col2meaning):\n",
    "    \"\"\"\n",
    "    Fill in missing type entries for each time period with zero duration.\n",
    "    \n",
    "    Ensures complete type coverage across all time periods by adding entries with \n",
    "    duration_h=0 for any type-time combinations that don't exist in the data.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with time-series data containing type and duration columns\n",
    "        time_col (str): Name of the time column (default: 'year_week')\n",
    "        unique_times (array-like, optional): Specific time periods to process. If None, uses all unique times from data\n",
    "        col2meaning (dict): Mapping of years (or \"default\") to expected type values\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original data with missing type entries added (duration_h=0), sorted by time and type\n",
    "    \"\"\"\n",
    "    unique_times = unique_times if unique_times is not None else data[time_col].unique()\n",
    "    \n",
    "    to_append = []\n",
    "    for week in unique_times:\n",
    "        entries = data[data[time_col] == week]\n",
    "        year = str(week.year) if type(week) is datetime else False\n",
    "        types = np.array(list(col2meaning[year].values()) if year and year in col2meaning else list(col2meaning[\"default\"].values()))\n",
    "\n",
    "        types_in_week = set(entries['type'].astype(str))\n",
    "\n",
    "        for t in set(types):\n",
    "            if t not in types_in_week:\n",
    "                to_append.append({'type': t, time_col: week, 'duration_h': 0})\n",
    "\n",
    "\n",
    "\n",
    "    data = pd.concat([data, pd.DataFrame(to_append)], ignore_index=True)\n",
    "    data = data.sort_values([time_col, 'type'])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(col2meaning.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"type_ind\" not in events.columns:\n",
    "    events.loc[:, 'type_ind'] = events.type\n",
    "\n",
    "type_year = []\n",
    "# add all number & year combinations\n",
    "for i, row in events.groupby([\"type_ind\", \"year\"]).agg({\"duration_h\": \"sum\"}).reset_index().iterrows():\n",
    "    type_year.append((row.type_ind, row.year))\n",
    "\n",
    "# for each combination, assign the proper type name\n",
    "for type_ind, year in type_year:\n",
    "    etype = get_event_type(type_ind, year)\n",
    "    # print(f'type_ind: {type_ind}, year: {year} --> {etype}')\n",
    "    mask = (events.type_ind == type_ind) & (events.year == year)\n",
    "    events.loc[mask, 'type'] = etype\n",
    "    # if len(events.loc[mask]) > 5:\n",
    "    #     display(events.loc[mask, [\"start\", \"type\", \"summary\", \"type_ind\"]].sample(5))\n",
    "    \n",
    "events.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_year = events.groupby(['type', 'year']).agg({'duration_h': \"sum\"}).reset_index()\n",
    "events_year = fill_in_missing_types(events_year, 'year', col2meaning=col2meaning)\n",
    "events_year = events_year.sort_values(['year', 'type'])\n",
    "events_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_week = events.groupby(['type', 'year_week']).agg({'duration_h': \"sum\"}).reset_index()\n",
    "events_week = fill_in_missing_types(events_week, 'year_week', events_all.year_week.unique())\n",
    "events_week['year'] = events_week.year_week.apply(lambda ts: ts.year)\n",
    "events_week = events_week.sort_values(['year_week', 'type'])\n",
    "events_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_yearly = events.groupby(['type', 'year']).agg({'summary': lambda x: x.unique()[-5:]}).reset_index().to_numpy()\n",
    "for row in event_type_yearly:\n",
    "    etype, year, summaries = row\n",
    "    print(f'Event type: {etype}')\n",
    "    print(f\"\\tyear: {year}\")\n",
    "    for s in summaries:\n",
    "        print('\\t', s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_colors['0'] = dict(background='blue')\n",
    "event_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2palette = {}\n",
    "for year in col2meaning:\n",
    "    palette = {\n",
    "        get_event_type(etype=c, year=year): event_colors[c]['background'] for c in event_colors\n",
    "    }\n",
    "    year2palette[year] = palette\n",
    "year2palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = str(int(round(p.get_height(),0)))\n",
    "            ax.text(_x, _y, value, ha=\"center\", fontsize=8) \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(12, 8), dpi=120, facecolor=\"w\")\n",
    "\n",
    "data = events.groupby(\"type\").agg({\"duration_d\": np.sum}).reset_index()\n",
    "\n",
    "sns.barplot(\n",
    "    data=data.sort_values(\"type\"), x=\"type\", y=\"duration_d\", hue=\"type\", ax=axes, palette=palette\n",
    ")\n",
    "show_values_on_bars(axes)\n",
    "plt.title(f\"Use of time per event type from 2015-{max_year}\")\n",
    "plt.ylabel(\"Total duration (days)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xticks(axes.get_xticks())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1,figsize=(12,8), dpi=120, facecolor='w')\n",
    "\n",
    "sns.barplot(data=events.sort_values('type'), x='type', y='duration_h', hue='type', ax=axes, palette=palette)\n",
    "plt.title('Distribution of event duration')\n",
    "plt.ylabel(\"Total duration (hours)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Event type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event types over time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agg = 'duration_h'\n",
    "data = events.groupby(['type', 'year']).agg({time_agg: \"sum\"}).reset_index()\n",
    "data = data.sort_values('year')\n",
    "\n",
    "n_years = data.year.nunique()\n",
    "\n",
    "top = 1.05 * data[time_agg].max()\n",
    "\n",
    "fig, axes = plt.subplots(n_years,1,figsize=(12,6*n_years), dpi=120, facecolor='w')\n",
    "\n",
    "for i, year in enumerate(data.year.unique()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    query = f'year == {year}'\n",
    "    sns.barplot(data=data.query(query).sort_values('type'), x='type', y=time_agg, ax=ax, palette=palette, hue='type')\n",
    "    ax.set_title(f'{year}')\n",
    "    ax.set_ylabel(f'Total duration ({time_agg.split(\"_\")[-1]})')\n",
    "    \n",
    "    show_values_on_bars(ax)\n",
    "    ax.set_ylim(top=top)\n",
    "    ax.xaxis.set_tick_params(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_events = events[events['type'] == \"default\"]\n",
    "for year in default_events.year.unique():\n",
    "    print(f'Year: {year}')\n",
    "    summaries = default_events[default_events.year == year]['summary'].sample(10)\n",
    "    for s in summaries:\n",
    "        print('\\t', s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2palette.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agg = 'duration_h'\n",
    "data = events_week\n",
    "n_years = data.year.nunique()\n",
    "print(f\"visualise {n_years} years of data: {data.year.unique()}\")\n",
    "\n",
    "# data = fill_in_missing_types(data, 'year_week')\n",
    "\n",
    "top = 1.05 * data[time_agg].max()\n",
    "\n",
    "fig, axes = plt.subplots(n_years,1,figsize=(12,6*n_years), dpi=120, facecolor='w')\n",
    "\n",
    "for i, year in enumerate(data.year.unique()):\n",
    "    ax = axes[i]\n",
    "    print(f'Processing year {year}...')\n",
    "    query = f'year == {year}'\n",
    "    pal = year2palette.get(str(year), palette)\n",
    "    data_year = data.query(query).sort_values('type')\n",
    "    type_replacaments = {}\n",
    "    for etype in data_year['type'].unique():\n",
    "        if etype not in pal:\n",
    "            print(f\"\\tWarning: type '{etype}' not found in palette for year {year}\")\n",
    "            new_type = col2meaning.get(str(year), col2meaning[\"default\"]).get(etype, 'unknown')\n",
    "            type_replacaments[etype] = new_type\n",
    "    if type_replacaments:\n",
    "        print(f'\\tReplacing types: {type_replacaments}')\n",
    "        data_year['type'] = data_year['type'].replace(type_replacaments)\n",
    "\n",
    "    sns.lineplot(data=data_year, x='year_week', y=time_agg, hue='type', ax=ax, palette=pal, estimator=None)\n",
    "    ax.set_title(f'{year}')\n",
    "    \n",
    "    ax.set_ylim(top=top)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in col2meaning:\n",
    "    print(f'Year: {year}')\n",
    "    etypes = col2meaning[year].values()\n",
    "    for i, t in enumerate(etypes):\n",
    "        print(i, t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_types = [types[5], types[7], types[9]]\n",
    "work_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agg = 'duration_h'\n",
    "\n",
    "any_work_hours = np.array([data[data.type == t][time_agg] for t in work_types]).sum(axis=0)\n",
    "any_work_hours[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = events_week\n",
    "\n",
    "fig, axes = plt.subplots(1,1,figsize=(18,8), dpi=120, facecolor='w')\n",
    "\n",
    "ax = axes\n",
    "\n",
    "\n",
    "query = f'type == \"{types[0]}\"'\n",
    "sns.lineplot(x=data.year_week.unique(), y=data.query(query)[time_agg], ax=ax, label=types[0])\n",
    "\n",
    "sns.lineplot(x=data.year_week.unique(), y=any_work_hours, ax=ax, label='efficient working hours')\n",
    "\n",
    "ax.axhline(37.5, ls='--', color='k', zorder=0, label='full work week')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Efficient working hours per week')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = pd.DataFrame(data={'year_week': data.year_week.unique(), 'working_h': any_work_hours})\n",
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['overtime'] = working_df.working_h.apply(lambda x: x >= 37.5)\n",
    "working_df['clear overtime'] = working_df.working_h.apply(lambda x: x >= 40)\n",
    "working_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busiest weeks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df_sorted = working_df.sort_values(['working_h', 'year_week'], ascending=[False, True]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to create a matrix for the heatmap\n",
    "heatmap_data_month = working_df.pivot_table(\n",
    "    index=working_df[\"year_week\"].dt.year,\n",
    "    columns=working_df[\"year_week\"].dt.month,\n",
    "    values=\"working_h\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0,\n",
    ").rename_axis(\"Month\", axis=1).rename_axis(\"Year\", axis=0)\n",
    "\n",
    "# Drop rows where the sum of the row is zero\n",
    "heatmap_data_month.drop(\n",
    "    heatmap_data_month.sum(axis=1)[heatmap_data_month.sum(axis=1) == 0].index, inplace=True\n",
    ")\n",
    "\n",
    "heatmap_data_month = heatmap_data_month / 7.5\n",
    "heatmap_data_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data_month, cmap=\"coolwarm\", cbar_kws={'label': 'Working Days (PWD); 21 days is a full working month'}, annot=True, fmt=\".0f\", center=21)\n",
    "plt.title(\"Heatmap of Work Time (PWD) by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to create a matrix for the heatmap\n",
    "heatmap_data_week = working_df.pivot_table(\n",
    "    index=working_df[\"year_week\"].dt.year,\n",
    "    columns=working_df[\"year_week\"].dt.isocalendar().week,\n",
    "    values=\"working_h\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0,\n",
    ").rename_axis(\"Week\", axis=1).rename_axis(\"Year\", axis=0)\n",
    "\n",
    "# remove w53\n",
    "heatmap_data_week.loc[:, 52] += heatmap_data_week.loc[:, 53]\n",
    "heatmap_data_week.drop(53, inplace=True, axis=1)\n",
    "\n",
    "# remove years before 2018\n",
    "heatmap_data_week = heatmap_data_week.loc[2018:]\n",
    "\n",
    "# Drop rows where the sum of the row is zero\n",
    "heatmap_data_week.drop(\n",
    "    heatmap_data_week.sum(axis=1)[heatmap_data_week.sum(axis=1) == 0].index, inplace=True\n",
    ")\n",
    "\n",
    "heatmap_data_week = heatmap_data_week / 7.5\n",
    "heatmap_data_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to create a matrix for the heatmap\n",
    "heatmap_data_overtime = working_df.pivot_table(\n",
    "    index=working_df[\"year_week\"].dt.year,\n",
    "    columns=working_df[\"year_week\"].dt.isocalendar().week,\n",
    "    values=\"overtime\",\n",
    "    # aggfunc=\"sum\",\n",
    "    fill_value=0,\n",
    ").rename_axis(\"Week\", axis=1).rename_axis(\"Year\", axis=0)\n",
    "\n",
    "heatmap_data_overtime.drop(53, inplace=True, axis=1)\n",
    "\n",
    "# # remove years before 2018\n",
    "heatmap_data_overtime = heatmap_data_overtime.loc[2018:]\n",
    "\n",
    "heatmap_data_overtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "plt.figure(figsize=(15, 8))\n",
    "how_much_overtime_week = (heatmap_data_week-5).where(heatmap_data_week > 5, other=0)\n",
    "sns.heatmap(heatmap_data_overtime, cmap=\"coolwarm\", cbar_kws={'label': 'Working Days (PWD); 5 days is a full work week'}, annot=how_much_overtime_week, fmt=\".0f\")\n",
    "plt.title(\"Heatmap of Weeks with Overtime (PWD) by Week\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(how_much_overtime_week, cmap=\"coolwarm\", cbar_kws={'label': 'Working Days (PWD); 5 days is a full work week'}, annot=True, fmt=\".0f\", center=1)\n",
    "plt.title(\"Heatmap of Weeks with Overtime (PWD) by Week\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of overtime days per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[\"year\"] = working_df.year_week.apply(lambda ts: ts.year)\n",
    "working_df[\"quarter\"] = working_df.year_week.apply(lambda ts: get_quarter(ts))\n",
    "working_df[\"year_quarter\"] = working_df.year_week.apply(lambda ts: f\"{ts.year}-Q{get_quarter(ts)}\")\n",
    "working_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working = working_df.copy().drop(columns=['overtime', 'clear overtime'])\n",
    "df_working.loc[:, \"overtime\"] = working_df.overtime.apply(lambda x: 'overtime' if x else 'no overtime')\n",
    "df_working.loc[:, \"clear overtime\"] = working_df[\"clear overtime\"].apply(lambda x: 'clear overtime' if x else 'no overtime')\n",
    "df_working.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"overtime\"\n",
    "df_overtime_yearly = df_working.groupby([y_col, 'year']).nunique()['year_week'].reset_index().sort_values('year')\n",
    "df_overtime_yearly.rename(columns={'year_week': 'n_weeks'}, inplace=True)\n",
    "df_overtime_quarterly = df_working.groupby([y_col, 'year_quarter']).nunique()['year_week'].reset_index().sort_values('year_quarter')\n",
    "df_overtime_quarterly.rename(columns={'year_week': 'n_weeks'}, inplace=True)\n",
    "df_overtime_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1,figsize=(12,6), dpi=120, facecolor='w')\n",
    "ax = axes[0]\n",
    "sns.barplot(data=df_overtime_yearly, x='year', y='n_weeks', hue=y_col, ax=ax)\n",
    "ax.axhline(47/2, ls='--', color='black', zorder=0, label='every other work week is overtime')\n",
    "ax.legend()\n",
    "ax.set_title('Overtime weeks per year')\n",
    "\n",
    "ax = axes[1]\n",
    "sns.barplot(data=df_overtime_quarterly, x='year_quarter', y='n_weeks', hue=y_col, ax=ax)\n",
    "ax.set_title('Overtime weeks per quarter')\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.set_xlabel('Year-Quarter')\n",
    "ax.axhline(52/4/2, ls='--', color='black', zorder=0, label='every other work week is overtime')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('Number of weeks')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calendar-helper (3.10.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
